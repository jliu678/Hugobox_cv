<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Marginal Distribution | Jiyuan Liu</title>
    <link>http://localhost:1313/tags/marginal-distribution/</link>
      <atom:link href="http://localhost:1313/tags/marginal-distribution/index.xml" rel="self" type="application/rss+xml" />
    <description>Marginal Distribution</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 24 Apr 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_fd2be5a69becaf9e.png</url>
      <title>Marginal Distribution</title>
      <link>http://localhost:1313/tags/marginal-distribution/</link>
    </image>
    
    <item>
      <title>üéì Math Derivation for ELBO/KL in Bayesian Inference and VAEs</title>
      <link>http://localhost:1313/post/19c.bayes_variational_infer_elbo/</link>
      <pubDate>Thu, 24 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/19c.bayes_variational_infer_elbo/</guid>
      <description>&lt;h2 id=&#34;-marginal-likelihood-is-often-intractable-in-bayesian-inference&#34;&gt;üîç Marginal likelihood is often intractable in Bayesian Inference&lt;/h2&gt;
&lt;p&gt;Bayesian inference and Variational Autoencoders (VAEs), a marriage of deep learning and Bayesian inference, are powerful and foundational for probabilistic modeling used in computational biology. But rely on the concept of marginal likelihood, which is often intractable to compute directly. This is because both frameworks typically involve integrating over latent variables or parameters, which can lead to high-dimensional integrals that are computationally intractable.&lt;/p&gt;
&lt;p&gt;Specifically, in Bayesian inference, we want the posterior distribution:&lt;/p&gt;

$$p(\theta \mid D) = \frac{p(D \mid \theta) \, p(\theta)}{p(D)} \tag{1}$$


&lt;p&gt;But the denominator‚Äîthe evidence or marginal likelihood‚Äîis:&lt;/p&gt;

$$p(D) = \int p(D \mid \theta) \, p(\theta) \, d\theta \tag{2}$$


&lt;p&gt;This integral is often intractable.&lt;/p&gt;
&lt;h2 id=&#34;-variational-inference-the-workaround&#34;&gt;üí° Variational Inference: The Workaround&lt;/h2&gt;
&lt;p&gt;We introduce a simpler variational distribution $q(\theta)$
 to approximate $p(\theta \mid D)$
, and we try to make $q$
 close to the true posterior.&lt;/p&gt;
&lt;p&gt;We measure closeness using KL divergence:&lt;/p&gt;

$$\text{KL}(q(\theta) \| p(\theta \mid D)) = \int q(\theta) \log \frac{q(\theta)}{p(\theta \mid D)} d\theta \tag{3}$$


&lt;p&gt;This is hard to compute directly because it involves $p(D)$
, so we rearrange terms.&lt;/p&gt;
&lt;p&gt;We can rewrite $\log p(D)$
 as:&lt;/p&gt;

$$\log p(D) = \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] + \text{KL}(q(\theta) \| p(\theta \mid D)) \tag{4}$$


&lt;p&gt;Thus:&lt;/p&gt;

$$\log p(D) = \text{ELBO}(q) + \text{KL}(q(\theta) \| p(\theta \mid D)) \tag{5}$$


&lt;p&gt;Since the KL divergence is always ‚â• 0:&lt;/p&gt;

$$\text{ELBO}(q) \leq \log p(D) \tag{6}$$


&lt;p&gt;That&amp;rsquo;s why it&amp;rsquo;s called a lower bound.&lt;/p&gt;
&lt;h2 id=&#34;-derive-elbo-and-kl&#34;&gt;üßÆ Derive ELBO and KL&lt;/h2&gt;
&lt;p&gt;Let $q(\theta)$
 be any distribution over $\theta$
 such that its support covers that of $p(\theta \mid D)$
. We&amp;rsquo;ll exploit a classic trick: insert $q(\theta)$
 into the log marginal likelihood using expectation and apply properties of KL divergence.&lt;/p&gt;
&lt;h3 id=&#34;step-1-start-with-log-evidence&#34;&gt;Step 1: Start with log evidence&lt;/h3&gt;
&lt;p&gt;We take the logarithm of $p(D)$
, and &amp;ldquo;multiply and divide&amp;rdquo; inside by $q(\theta)$
:&lt;/p&gt;

$$\log p(D) = \log \int \frac{q(\theta)}{q(\theta)} p(D \mid \theta) p(\theta) d\theta \tag{7}$$



$$= \log \int q(\theta) \cdot \frac{p(D \mid \theta) p(\theta)}{q(\theta)} d\theta \tag{8}$$



$$= \log \mathbb{E}_{q(\theta)} \left[ \frac{p(D \mid \theta) p(\theta)}{q(\theta)} \right] \tag{9}$$


&lt;p&gt;This is Jensen&amp;rsquo;s inequality time.&lt;/p&gt;
&lt;h3 id=&#34;step-2-apply-jensens-inequality&#34;&gt;Step 2: Apply Jensen&amp;rsquo;s Inequality&lt;/h3&gt;

$$\log \mathbb{E}_{q(\theta)} \left[ \frac{p(D \mid \theta) p(\theta)}{q(\theta)} \right] \geq \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D \mid \theta) p(\theta)}{q(\theta)} \right] \tag{10}$$


&lt;p&gt;That gives us the ELBO:&lt;/p&gt;

$$\text{ELBO}(q) = \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] \tag{11}$$


&lt;p&gt;So:&lt;/p&gt;

$$\log p(D) \geq \text{ELBO}(q) \tag{12}$$


&lt;p&gt;But we can go further ‚Äî let&amp;rsquo;s rewrite $\log p(D)$
 exactly in terms of ELBO + KL divergence.&lt;/p&gt;
&lt;h3 id=&#34;step-3-add-and-subtract-the-same-quantity&#34;&gt;Step 3: Add and Subtract the Same Quantity&lt;/h3&gt;
&lt;p&gt;We now write:&lt;/p&gt;

$$\log p(D) = \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] + \left( \log p(D) - \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] \right) \tag{13}$$


&lt;p&gt;Now we observe that the term in parentheses is exactly the KL divergence between $q(\theta)$
 and the true posterior:&lt;/p&gt;

$$\text{KL}(q(\theta) \| p(\theta \mid D)) = \mathbb{E}_{q(\theta)} \left[ \log \frac{q(\theta)}{p(\theta \mid D)} \right] \tag{14}$$


&lt;p&gt;But recall:&lt;/p&gt;

$$p(\theta \mid D) = \frac{p(D, \theta)}{p(D)} \Rightarrow \log p(\theta \mid D) = \log p(D, \theta) - \log p(D) \tag{15}$$


&lt;p&gt;Then:&lt;/p&gt;

$$\log \frac{q(\theta)}{p(\theta \mid D)} = \log \frac{q(\theta)}{p(D, \theta)} + \log p(D) \tag{16}$$


&lt;p&gt;Take expectation over $q(\theta)$
:&lt;/p&gt;

$$\text{KL}(q(\theta) \| p(\theta \mid D)) = -\mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] + \log p(D) \tag{17}$$


&lt;p&gt;Rearranged:&lt;/p&gt;

$$\log p(D) = \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] + \text{KL}(q(\theta) \| p(\theta \mid D)) \tag{18}$$


&lt;h3 id=&#34;definition-of-expectation-used-above&#34;&gt;Definition of Expectation used above&lt;/h3&gt;
&lt;p&gt;Note the above derivations used multiple times the definition that &lt;strong&gt;expectation of a function $f(\theta)$
 under a probability distribution $q(\theta)$
&lt;/strong&gt; is:&lt;/p&gt;

$$\mathbb{E}_{q(\theta)}[f(\theta)] = \int q(\theta) \, f(\theta) \, d\theta \tag{19}$$


&lt;h2 id=&#34;-elbo-expression-used-in-vaes&#34;&gt;üìê ELBO Expression used in VAEs&lt;/h2&gt;

$$\text{ELBO}(q) = \mathbb{E}_{q(\theta)}[\log p(D \mid \theta)] - \text{KL}(q(\theta) \| p(\theta)) \tag{20}$$


&lt;p&gt;This is the most widely used form in variational inference and VAEs. It comes from expanding the joint $p(D, \theta)$, and interpreting the ELBO as a trade-off between reconstruction and regularization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first term encourages $q(\theta)$
 to explain the data well.&lt;/li&gt;
&lt;li&gt;The second term encourages $q(\theta)$
 to stay close to the prior.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Its derivation start from:&lt;/p&gt;
&lt;h3 id=&#34;1-elbokl-decomposition&#34;&gt;1. ELBO‚ÄìKL decomposition:&lt;/h3&gt;

$$\log p(D) = \text{ELBO}(q) + \text{KL}(q(\theta) \| p(\theta \mid D)) \tag{5}$$


&lt;p&gt;This is always true by the definition of the Kullback-Leibler divergence and Jensen&amp;rsquo;s inequality. Rearranging:&lt;/p&gt;

$$\text{ELBO}(q) = \log p(D) - \text{KL}(q(\theta) \| p(\theta \mid D)) \tag{22}$$


&lt;h3 id=&#34;2-definition-of-elbo-via-expected-joint&#34;&gt;2. Definition of ELBO via expected joint:&lt;/h3&gt;
&lt;p&gt;Alternatively, ELBO is often defined as:&lt;/p&gt;

$$\text{ELBO}(q) = \mathbb{E}_{q(\theta)} \left[ \log \frac{p(D, \theta)}{q(\theta)} \right] = \mathbb{E}_{q(\theta)}[\log p(D, \theta)] - \mathbb{E}_{q(\theta)}[\log q(\theta)] \tag{23}$$


&lt;p&gt;Now recall:&lt;/p&gt;

$$\log p(D, \theta) = \log p(D \mid \theta) + \log p(\theta) \tag{24}$$


&lt;p&gt;So:&lt;/p&gt;

$$\text{ELBO}(q) = \mathbb{E}_{q(\theta)}[\log p(D \mid \theta)] + \mathbb{E}_{q(\theta)}[\log p(\theta)] - \mathbb{E}_{q(\theta)}[\log q(\theta)] \tag{25}$$


&lt;p&gt;Group terms:&lt;/p&gt;

$$\text{ELBO}(q) = \mathbb{E}_{q(\theta)}[\log p(D \mid \theta)] - \text{KL}(q(\theta) \| p(\theta)) \tag{20}$$


</description>
    </item>
    
    <item>
      <title>üßÆ Math Derivation for scRNAseq Imputation (SAVER)</title>
      <link>http://localhost:1313/post/19b.scrnaseq_impute_saver/</link>
      <pubDate>Thu, 24 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/19b.scrnaseq_impute_saver/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Single-cell RNASeq could have a large amount of zero values, representing either missing data or no expression. Imputation approaches to deal with this issue have the risk of generating false positive or irreproducible results. Model-based imputation generate fewer false-positives compared with data smoothing based methods (MAGIC and knn-smooth), but this varied greatly depending on how well the model described the datasets.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41592-018-0033-z#Sec2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAVER&lt;/a&gt; was the least likely to generate false or irreproducible results in &lt;a href=&#34;https://f1000research.com/articles/7-1740/v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a benchmark of common imputation methods&lt;/a&gt;. It suggests the mathematical model used in SAVER could well depict the structure inherent to the scRNAseq datasets. Here we will derive the Poisson‚Äìgamma mixture model (also known as negative binomial model) and its Bayesian framework used in SAVER that leverage conjugate priors to estimate the posterior distribution of gene expression levels.&lt;/p&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;p&gt;more in another md file&lt;/p&gt;
&lt;h2 id=&#34;-goal&#34;&gt;‚úÖ Goal:&lt;/h2&gt;
 
$$
 \hat{\lambda}_{gc} = \frac{Y_{gc} + \hat{\alpha}_{gc}}{s_c + \hat{\beta}_{gc}} = \frac{s_c}{s_c + \hat{\beta}_{gc}} \cdot \frac{Y_{gc}}{s_c} + \frac{\hat{\beta}_{gc}}{s_c + \hat{\beta}_{gc}} \cdot \hat{\mu}_{gc} 
$$


&lt;p&gt;&lt;strong&gt;Gamma distribution gives:&lt;/strong&gt;&lt;/p&gt;
 
$$ \hat{\alpha}_{gc} = \hat{\beta}_{gc} \hat{\mu}_{gc} \quad \text{(1)} $$


&lt;h2 id=&#34;-step-by-step-proof&#34;&gt;üîÅ Step-by-Step Proof:&lt;/h2&gt;
&lt;p&gt;We start with:&lt;/p&gt;
 
$$ \hat{\lambda}_{gc} = \frac{Y_{gc} + \hat{\alpha}_{gc}}{s_c + \hat{\beta}_{gc}} \quad \text{(2)} $$


&lt;p&gt;Substitute  $\hat{\alpha}_{gc} = \hat{\beta}_{gc} \hat{\mu}_{gc}$ 
 from equation (1):&lt;/p&gt;
 
$$ = \frac{Y_{gc} + \hat{\beta}_{gc} \hat{\mu}_{gc}}{s_c + \hat{\beta}_{gc}} \quad \text{(3)} $$


&lt;p&gt;Split the numerator:&lt;/p&gt;
 
$$ = \frac{Y_{gc}}{s_c + \hat{\beta}_{gc}} + \frac{\hat{\beta}_{gc} \hat{\mu}_{gc}}{s_c + \hat{\beta}_{gc}} \quad \text{(4)} $$


&lt;p&gt;Now multiply and divide the first term by  $s_c$ 
:&lt;/p&gt;
 
$$ = \left(\frac{s_c}{s_c + \hat{\beta}_{gc}} \cdot \frac{Y_{gc}}{s_c}\right) + \left(\frac{\hat{\beta}_{gc}}{s_c + \hat{\beta}_{gc}} \cdot \hat{\mu}_{gc}\right) \quad \text{(5)} $$


&lt;p&gt;Which gives:&lt;/p&gt;
 
$$ \hat{\lambda}_{gc} = \frac{s_c}{s_c + \hat{\beta}_{gc}} \cdot \frac{Y_{gc}}{s_c} + \frac{\hat{\beta}_{gc}}{s_c + \hat{\beta}_{gc}} \cdot \hat{\mu}_{gc} \quad \text{(6)} $$


&lt;p&gt;‚úÖ &lt;strong&gt;Proved.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;-summary&#34;&gt;üîç Summary:&lt;/h2&gt;
&lt;p&gt;This is a weighted average of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; $\frac{Y_{gc}}{s_c}$ 
: observed normalized expression&lt;/li&gt;
&lt;li&gt; $\hat{\mu}_{gc}$ 
: predicted expression from prior&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With weights proportional to data confidence ( $s_c$ 
) and prior confidence ( $\hat{\beta}_{gc}$ 
).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üìä Math Derivation in Bayesian Inference-- Bypassing Marginals Using Conjugate Priors</title>
      <link>http://localhost:1313/post/19a.conjugate_prior_bayes/</link>
      <pubDate>Sat, 12 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/19a.conjugate_prior_bayes/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Conjugate priors are a powerful concept in Bayesian statistics that allow us to simplify the process of updating our beliefs about a parameter given new data. Using conjugate priors allows you to bypass computing marginal distributions because the posterior has the same functional form as the prior, making the normalization constant analytically tractable.&lt;/p&gt;
&lt;h4 id=&#34;standard-bayes-theorem&#34;&gt;Standard Bayes&amp;rsquo; Theorem&lt;/h4&gt;
 $$P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}$$ 

&lt;p&gt;where the marginal likelihood is:&lt;/p&gt;
 $$P(D) = \int P(D|\theta)P(\theta)d\theta$$ 

&lt;h4 id=&#34;the-problem&#34;&gt;The Problem&lt;/h4&gt;
&lt;p&gt;Computing  $P(D)$ 
 often requires intractable integrals, especially in high dimensions.&lt;/p&gt;
&lt;h4 id=&#34;conjugate-prior-solution&#34;&gt;Conjugate Prior Solution&lt;/h4&gt;
&lt;p&gt;When the prior  $P(\theta)$ 
 is conjugate to the likelihood  $P(D|\theta)$ 
, we have:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Prior:&lt;/strong&gt;  $P(\theta) \propto f(\theta; \alpha_0)$ 
 (some parametric form)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Likelihood:&lt;/strong&gt;  $P(D|\theta) \propto g(\theta; D)$ 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Posterior:&lt;/strong&gt;  $P(\theta|D) \propto f(\theta; \alpha_n)$ 
 (same form as prior)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;where  $\alpha_n = h(\alpha_0, D)$ 
 is a simple update function. Specifically, since we know the posterior belongs to the same family as the prior, we can write:&lt;/p&gt;
 $$P(\theta|D) = \frac{f(\theta; \alpha_n)}{Z(\alpha_n)}$$ 

&lt;p&gt;where  $Z(\alpha_n)$ 
 is the normalization constant for the known distribution family, which has a closed form.&lt;/p&gt;
&lt;h2 id=&#34;example-beta-binomial-conjugacy&#34;&gt;Example: Beta-Binomial Conjugacy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Prior:&lt;/strong&gt;  $P(\theta) = \text{Beta}(\alpha, \beta)$ 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Likelihood:&lt;/strong&gt;  $P(D|\theta) = \text{Binomial}(n, \theta)$ 
 with  $s$ 
 successes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Posterior:&lt;/strong&gt;  $P(\theta|D) = \text{Beta}(\alpha + s, \beta + n - s)$ 
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We never need to compute:&lt;/p&gt;
 $$P(D) = \int_0^1 \binom{n}{s}\theta^s(1-\theta)^{n-s} \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta$$ 

&lt;p&gt;Instead, we directly get the posterior parameters and use the known Beta normalization. This explains why conjugate priors are so powerful&amp;ndash; they let us skip the hardest part of Bayesian computation. Let me break down what&amp;rsquo;s happening:&lt;/p&gt;
&lt;h4 id=&#34;the-hard-way-without-conjugate-priors&#34;&gt;The Hard Way (Without Conjugate Priors)&lt;/h4&gt;
&lt;p&gt;To get the posterior, we&amp;rsquo;d normally need to compute this integral:&lt;/p&gt;
 $$P(D) = \int_0^1 \binom{n}{s}\theta^s(1-\theta)^{n-s} \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta$$ 

&lt;p&gt;This integral combines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; $\binom{n}{s}\theta^s(1-\theta)^{n-s}$ 
 (binomial likelihood)&lt;/li&gt;
&lt;li&gt; $\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}$ 
 (Beta prior)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;why-this-integral-is-nasty&#34;&gt;Why This Integral is Nasty&lt;/h4&gt;
&lt;p&gt;Even though this particular integral has a closed form, in general such integrals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;May not have analytical solutions&lt;/li&gt;
&lt;li&gt;Require numerical integration (expensive, approximate)&lt;/li&gt;
&lt;li&gt;Get exponentially harder in higher dimensions&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;the-conjugate-prior-shortcut&#34;&gt;The Conjugate Prior Shortcut&lt;/h4&gt;
&lt;p&gt;Instead of computing that integral, we use the conjugate relationship:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Recognize the pattern:&lt;/strong&gt;
 $$\theta^s(1-\theta)^{n-s} \times \theta^{\alpha-1}(1-\theta)^{\beta-1} = \theta^{(s+\alpha)-1}(1-\theta)^{(n-s+\beta)-1} \quad (1)$$
&lt;/p&gt;
&lt;p&gt;This looks like a Beta distribution with parameters  $(\alpha + s, \beta + n - s)$ 
&lt;/p&gt;
&lt;p&gt;We derive below in &lt;a href=&#34;#math-derivation&#34;&gt;next section&lt;/a&gt; how this leads to the marginal likelihood:&lt;/p&gt;
 $$P(D) = \frac{B(\alpha+s, \beta+n-s)}{B(\alpha, \beta)} \binom{n}{s} \quad (2)$$ 

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Write the posterior directly:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We substitute equation (1) and (2) in Standard Bayes&amp;rsquo; Theorem to get the posterior distribution:&lt;/p&gt;
 $$P(\theta|D) = \text{Beta}(\alpha + s, \beta + n - s) = \frac{\theta^{\alpha+s-1}(1-\theta)^{\beta+n-s-1}}{B(\alpha+s, \beta+n-s)}$$ 

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But for getting the posterior distribution, we don&amp;rsquo;t even need  $P(D)$ 
 - we just need the updated parameters!&lt;/p&gt;
&lt;h4 id=&#34;interim-summary&#34;&gt;Interim Summary&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Without conjugacy:&lt;/em&gt; Solve a potentially intractable integral&lt;/li&gt;
&lt;li&gt;&lt;em&gt;With conjugacy:&lt;/em&gt; Simple parameter update:  $(\alpha, \beta) \rightarrow (\alpha + s, \beta + n - s)$ 
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The normalization &amp;ldquo;just works&amp;rdquo; because we&amp;rsquo;re staying within the same distributional family where normalization constants are known.&lt;/p&gt;
&lt;h2 id=&#34;math-derivation&#34;&gt;Math Derivation&lt;a id=&#34;math-derivation&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Below is a &lt;strong&gt;step-by-step derivation of the marginal likelihood integral for the Beta-Binomial conjugate prior relationship&lt;/strong&gt;. This shows how we can transform a potentially difficult integral into a simple ratio of Beta functions, which is the essence of why conjugate priors are so powerful in Bayesian inference.&lt;/p&gt;
&lt;h3 id=&#34;starting-point-the-marginal-likelihood-integral&#34;&gt;Starting Point: The Marginal Likelihood Integral&lt;/h3&gt;
 $$P(D) = \int_0^1 \binom{n}{s}\theta^s(1-\theta)^{n-s} \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \quad (1)$$ 

&lt;h3 id=&#34;step-1-factor-out-constants&#34;&gt;Step 1: Factor Out Constants&lt;/h3&gt;
&lt;p&gt;The binomial coefficient  $\binom{n}{s}$ 
 and  $\frac{1}{B(\alpha,\beta)}$ 
 don&amp;rsquo;t depend on  $\theta$ 
, so we can pull them outside the integral:&lt;/p&gt;
 $$P(D) = \binom{n}{s} \cdot \frac{1}{B(\alpha,\beta)} \int_0^1 \theta^s(1-\theta)^{n-s} \cdot \theta^{\alpha-1}(1-\theta)^{\beta-1} d\theta \quad (2)$$ 

&lt;h3 id=&#34;step-2-combine-the-powers&#34;&gt;Step 2: Combine the Powers&lt;/h3&gt;
&lt;p&gt;Using the exponent rule  $x^a \cdot x^b = x^{a+b}$ 
:&lt;/p&gt;
 $$P(D) = \binom{n}{s} \cdot \frac{1}{B(\alpha,\beta)} \int_0^1 \theta^{s+\alpha-1}(1-\theta)^{n-s+\beta-1} d\theta \quad (3)$$ 

&lt;h3 id=&#34;step-3-recognize-the-beta-function-integral&#34;&gt;Step 3: Recognize the Beta Function Integral&lt;/h3&gt;
&lt;p&gt;The integral  $\int_0^1 \theta^{a-1}(1-\theta)^{b-1} d\theta$ 
 is exactly the definition of the Beta function  $B(a,b)$ 
.&lt;/p&gt;
&lt;p&gt;In our case, we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; $a = s + \alpha$ 
&lt;/li&gt;
&lt;li&gt; $b = n - s + \beta$ 
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So:
 $$\int_0^1 \theta^{s+\alpha-1}(1-\theta)^{n-s+\beta-1} d\theta = B(s+\alpha, n-s+\beta) = B(\alpha+s, \beta+n-s) \quad (4)$$ 
&lt;/p&gt;
&lt;h3 id=&#34;step-4-substitute-back&#34;&gt;Step 4: Substitute Back&lt;/h3&gt;
 $$P(D) = \binom{n}{s} \cdot \frac{1}{B(\alpha,\beta)} \cdot B(\alpha+s, \beta+n-s) \quad (5)$$ 

&lt;h3 id=&#34;final-result&#34;&gt;Final Result&lt;/h3&gt;
&lt;p&gt;Rearranging:
 $$P(D) = \frac{B(\alpha+s, \beta+n-s)}{B(\alpha,\beta)} \binom{n}{s} \quad (6)$$ 
&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;This is why conjugate priors are so computationally elegant: they transform intractable integrals into simple ratios of known functions. Specifically for the Beta-Binomial case:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;We avoided numerical integration&lt;/strong&gt; - instead of computing a potentially difficult integral, we used the known relationship between integrals and Beta functions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Both Beta functions have closed forms&lt;/strong&gt; -  $B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$ 
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;This gives us the exact marginal likelihood&lt;/strong&gt; - no approximation needed&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
